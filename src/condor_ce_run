#!/usr/bin/python
import os
import re
import sys
import time
import errno
import socket
import tempfile
import optparse
import traceback

import htcondor

# HTCondor-CE simple run script.
# Mimics the venerable condor_run

submit_file = """\
universe = grid
grid_resource = condor %(schedd_name)s %(collector_name)s
remove_universe = %(universe)s

executable = %(command)s
arguments = %(arguments)s

output = %(stdout_file)s
error = %(stderr_file)s
log = %(log_file)s

ShouldTransferFiles = YES
WhenToTransferOutput = ON_EXIT
getenv = True

use_x509userproxy = true

queue
"""

submit_remote_file = """\
universe = %(universe)s

executable = %(command)s
arguments = %(arguments)s
output = %(stdout_file)s
error = %(stderr_file)s
log = %(log_file)s

ShouldTransferFiles = YES
WhenToTransferOutput = ON_EXIT
getenv = True

use_x509userproxy = true

+Owner = undefined
+LeaveJobInQueue = ( StageOutFinish > 0 ) =!= true

queue
"""

class CondorRunException(Exception):
    pass

def parse_opts():
    parser = optparse.OptionParser()
    parser.add_option("-x", "--extra-attributes-file",
        help="A file containing additional HTCondor ClassAd attributes to " \
             "append to the submit ClassAd.",
        dest="extra_attrs_file")
    parser.add_option("-s", "--schedd-name",
        help="Name of the schedd to use.",
        dest="schedd_name")
    parser.add_option("-d", "--debug", help="Print debugging info. Set " \
        "environmental variable 'CONDOR_CE_RUN_DEBUG' to true to print " \
        "stacktraces",
        dest="debug", default=False, action="store_true")
    parser.add_option("-r", "--remote", help="Submit directly to remote " \
        "schedd, bypassing the local one.", dest="remote", default=False,
        action="store_true")
    parser.add_option("-l", "--local", help="Have the job run in the CE's " \
        "local universe.", dest="local", default=False, action="store_true")
    parser.add_option("-n", "--no-clean", help="Do not clean temporary "
        "files.", dest="clean", default=False, action="store_true")
    parser.disable_interspersed_args()

    opts, args = parser.parse_args()

    return opts, args

def generate_run_script(job_info):

    if job_info['command'][0] != '/':
        for dir in os.environ.get("PATH", "").split(":"):
            test_path = os.path.join(dir, job_info['command'])
            if os.path.exists(test_path):
                job_info['command'] = test_path
                break

    if job_info['arguments']:
        job_info['arguments'] = '"%s"' % ' '.join(["'%s'" % i for i in \
            job_info['arguments']])
    else:
        job_info['arguments'] = ''

    pid = os.getpid()

    fd, job_info['stdout_file'] = tempfile.mkstemp(dir=".",
        prefix=".stdout_%d_" % pid)
    os.close(fd)

    fd, job_info['stderr_file'] = tempfile.mkstemp(dir=".",
        prefix=".stderr_%d_" % pid)
    os.close(fd)

    fd, job_info['log_file'] = tempfile.mkstemp(dir=".",
        prefix=".log_%d_" % pid)
    os.close(fd)

    fd, job_info['submit_file'] = tempfile.mkstemp(dir=".",
        prefix=".submit_%d_" % pid)

    try:
        if job_info['remote']:
            os.write(fd, submit_remote_file % job_info)
        else:
            os.write(fd, submit_file % job_info)
    finally:
        os.close(fd)

# Example output: 1 job(s) submitted to cluster 14.
cluster_re = re.compile("(\d+) job\(s\) submitted to cluster (\d+)\.")
def submit_job(job_info):
    # TODO: Here and in wait_job below, make sure we can tell the difference
    # between condor_submit failure and failure to exec.
    args = ['condor_submit', job_info['submit_file']]
    if job_info['debug']:
        args.append("-debug")

    if job_info['remote']:
        args += ['-remote', job_info['schedd_name'], '-pool', job_info['collector_name']]

    r, w = os.pipe()
    pid = os.fork()
    if pid == 0:
        try:
            os.close(r)
            os.dup2(w, 1)
            os.execvp("condor_submit", args)
        finally:
            os._exit(1)
    os.close(w)

    for line in os.fdopen(r).readlines():
        m = cluster_re.match(line)
        if m:
            job_info['cluster'] = m.groups()[1]

    if job_info['remote'] and ('cluster' not in job_info):
        raise CondorRunException("Could not parse job cluster from " \
            "condor_submit output")

    tmp_pid = -1
    while tmp_pid != pid:
        tmp_pid, status = os.waitpid(pid, 0)
    if os.WIFEXITED(status):
        exit_code = os.WEXITSTATUS(status)
        if exit_code:
            raise CondorRunException("Failed to submit job; condor_submit " \
                "exited with code %d." % exit_code)
    elif os.WIFSIGNALED(status):
        signal = os.WTERMSIG(status)
        raise CondorRunException("Failed to submit job; condor_submit " \
            "terminated with signal %d." % signal)
    else:
        raise CondorRunException("Failed to submit job; condor_submit " \
            "stopped with unhandled status code %d." % status)

def wait_for_job(job_info):
    if job_info['remote']:
        return wait_for_job_remote(job_info)

    args = ['condor_wait', job_info['log_file']]
    if job_info['debug']:
        args.append("-debug")

    pid = os.fork()
    if pid == 0:
        try:
           fd = os.open(os.devnull, os.O_WRONLY)
           os.dup2(fd, 1)
           os.execvp("condor_wait", args)
        finally:
           os._exit(1)

    tmp_pid = -1
    while tmp_pid != pid:
        tmp_pid, status = os.waitpid(pid, 0)
    if os.WIFEXITED(status):
        exit_code = os.WEXITSTATUS(status)
        if exit_code:
            raise CondorRunException("Failed to wait for job; condor_wait " \
                "exited with code %d." % exit_code)
    elif os.WIFSIGNALED(status):
        signal = os.WTERMSIG(status)
        raise CondorRunException("Failed to wait for job; condor_wait " \
            "terminated with signal %d." % signal)
    else:
        raise CondorRunException("Failed to wait for job; condor_wait " \
            "stopped with unhandled status code %d." % status)

status_re = re.compile("(\d+)")
def check_remote_status(job_info):
    args = ['condor_q', '-format', '%d\n', 'JobStatus', '-pool',
        job_info['collector_name'], '-name', job_info['schedd_name'],
        job_info['cluster']]
    if job_info['debug']:
        args.append('-debug')

    r, w = os.pipe()
    pid = os.fork()
    if pid == 0:
        try:
            os.close(r)
            os.dup2(w, 1)
            os.execvp("condor_q", args)
        finally:
            os._exit(1)
    os.close(w)

    job_status = None
    for line in os.fdopen(r).readlines():
        m = status_re.match(line)
        if m:
            job_status = int(m.groups()[0])

    tmp_pid = -1
    while tmp_pid != pid:
        tmp_pid, status = os.waitpid(pid, 0)
    if os.WIFEXITED(status):
        exit_code = os.WEXITSTATUS(status)
        if exit_code:
            raise CondorRunException("Failed to check job status; condor_q " \
                "exited with code %d." % exit_code)
    elif os.WIFSIGNALED(status):
        signal = os.WTERMSIG(status)
        raise CondorRunException("Failed to check job status; condor_q " \
            "terminated with signal %d." % signal)
    else:
        raise CondorRunException("Failed to check job status; condor_q " \
            "stopped with unhandled status code %d." % status)

    if job_status == None:
        raise CondorRunException("condor_q did not return a valid job status.")

    return job_status

def wait_for_job_remote(job_info):
    while check_remote_status(job_info) != 4:
        time.sleep(1)

    args = ['condor_transfer_data', '-pool', job_info['collector_name'],
        '-name', job_info['schedd_name'], job_info['cluster']]
    if job_info['debug']:
        args.append('-debug')

    r, w = os.pipe()
    pid = os.fork()
    if pid == 0:
        try:
            os.close(r)
            os.dup2(w, 1)
            os.execvp("condor_transfer_data", args)
        finally:
            os._exit(1)
    os.close(w)

    tmp_pid = -1
    while tmp_pid != pid:
        tmp_pid, status = os.waitpid(pid, 0)
    if os.WIFEXITED(status):
        exit_code = os.WEXITSTATUS(status)
        if exit_code:
            raise CondorRunException("Failed to retrieve job output sandbox; condor_transfer_data " \
                "exited with code %d." % exit_code)
    elif os.WIFSIGNALED(status):
        signal = os.WTERMSIG(status)
        raise CondorRunException("Failed to retrieve job output sandbox; condor_transfer_data " \
            "terminated with signal %d." % signal)
    else:
        raise CondorRunException("Failed to retrieve job output sandbox; condor_transfer_data " \
            "stopped with unhandled status code %d." % status)

def print_results(job_info):

    for line in open(job_info["stdout_file"], "r").readlines():
        print line,

    for line in open(job_info["stderr_file"], "r").readlines():
        print line,

def cleanup(job_info):

    if 'log_file' in job_info:
        try:
            os.unlink(job_info['log_file'])
        except OSError, oe:
            if oe.errno != errno.ENOENT:
                raise

    if 'stdout_file' in job_info:
        try:
            os.unlink(job_info['stdout_file'])
        except OSError, oe:
            if oe.errno != errno.ENOENT:
                raise

    if 'stderr_file' in job_info:
        try:
            os.unlink(job_info['stderr_file'])
        except OSError, oe:
            if oe.errno != errno.ENOENT:
                raise

    if 'submit_file' in job_info:
        try:
            os.unlink(job_info['submit_file'])
        except OSError, oe:
            if oe.errno != errno.ENOENT:
                raise

def configureAuth():
    try:
        auth_methods = re.split(",?\s*", htcondor.param['SEC_CLIENT_AUTHENTICATION_METHODS'])
    except KeyError:
        auth_methods = []
    if 'GSI' not in auth_methods:
        auth_methods.append("GSI")

    auth_methods = ",".join(auth_methods)
    os.environ['_condor_SEC_CLIENT_AUTHENTICATION_METHODS'] = auth_methods
    htcondor.param['SEC_CLIENT_AUTHENTICATION_METHODS'] = auth_methods

def main():
    opts, args = parse_opts()
    configureAuth()

    if len(args) < 2:
        print "Usage: condor_ce_run <hostname> <command> [arg1] [arg2] [...]"
        return 1

    collector_hostname = args[0].split(":")[0]
    collector_hostname = socket.getfqdn(collector_hostname)
    port_info = args[0].split(":")[1:]
    if port_info:
        collector_hostname = "%s:%s" % (collector_hostname, port_info[0])
    else:
        collector_hostname = "%s:9619" % collector_hostname
    job_info = {'collector_name': collector_hostname, 'command': args[1]}
    if opts.schedd_name:
        job_info['schedd_name'] = opts.schedd_name
    else:
        job_info['schedd_name'] = collector_hostname.split(":")[0]

    job_info['debug'] = opts.debug
    os.environ.setdefault("TOOL_DEBUG", "D_FULLDEBUG")

    job_info['remote'] = opts.remote

    job_info['arguments'] = args[2:]

    if opts.local:
        job_info['universe'] = "local"
    else:
        job_info['universe'] = "vanilla"

    try:
        generate_run_script(job_info)
        submit_job(job_info)
        wait_for_job(job_info)
        print_results(job_info)
    finally:
        if opts.clean:
            cleanup(job_info)

    return 0

if __name__ == '__main__':
    try:
        sys.exit(main())
    except CondorRunException, e:
        try:
            if os.environ['CONDOR_CE_RUN_DEBUG'].lower() == 'true':
                traceback.print_exc()
        except KeyError:
            print e
